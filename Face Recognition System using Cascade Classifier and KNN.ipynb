{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing python script that captures images from webcam\n",
    "#Stores Face Info as numpy Array\n",
    "\n",
    "#Steps:\n",
    "#1. Read and show video stream ,capture images\n",
    "#2. Detect face and show bounding box\n",
    "#3. Flatten the largest face image and save in numpy array\n",
    "#4. Repeat the above for multiple people to generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name of Person: Tushar\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "(37, 30000)\n",
      "data saved at./data/Tushar.npy\n"
     ]
    }
   ],
   "source": [
    "#starting the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#face Detection\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "skip=0\n",
    "face_data = []\n",
    "dataset_path = './data/'\n",
    "\n",
    "file_name = input(\"Enter name of Person: \")\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        continue\n",
    "    #converting captured image into gray scale    \n",
    "    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
    "    #1.3 is the scaling factor i.e. Parameter specifying how much the image size is reduced at each image scale.\n",
    "    #This scale factor is used to create scale pyramid.Suppose, the scale factor is 1.03, it means we're using a small step for resizing, i.e. reduce size by 3 %\n",
    "    #we increase the chance of a matching size with the model for detection is found, while it's expensive.\n",
    "    \n",
    "    #and 5 is the minNeighbor.Parameter specifying how many neighbors each candidate rectangle should have to retain it. \n",
    "    #This parameter will affect the quality of the detected faces: higher value results in less detections but with higher quality.\n",
    "    \n",
    "    faces = sorted(faces , key = lambda f:f[2]*f[3])\n",
    "    #sort faces on basis of maxm size of the face is obtained.\n",
    "    #like 2 faces are present in frame with width and height of (25,25) and (50,50)\n",
    "    #then face is sorted on basis of which there product comes out to be maxm\n",
    "    \n",
    "    \n",
    "    for face in faces[-1:]:\n",
    "        x,y,w,h = face\n",
    "        cv2.rectangle(frame,(x-15,y-15),(x+w+15,y+h+15),(0,255,255),4)\n",
    "        #plotting rectangle around the face\n",
    "        \n",
    "        face_section = frame[y-15:y+h+15,x-15:x+w+15]\n",
    "        face_section = cv2.resize(face_section ,(100,100))\n",
    "        #face area is extracted\n",
    "        \n",
    "        skip += 1\n",
    "        if (skip%10 == 0 ):\n",
    "            face_data.append(face_section)\n",
    "            #only every 10th frame is appended to the face_data\n",
    "            print(len(face_data))\n",
    "            \n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow(\"Face Section\",face_section)\n",
    "    \n",
    "    key_pressed = cv2.waitKey(1) & 0xFF\n",
    "    #continuing capturing data untill q key is pressed\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "        \n",
    "#converting face list array into numpy array\n",
    "face_data = np.asarray(face_data)\n",
    "face_data = face_data.reshape((face_data.shape[0],-1))\n",
    "print(face_data.shape)\n",
    "\n",
    "np.save(dataset_path + file_name +'.npy',face_data )\n",
    "print(\"data saved at\" + dataset_path + file_name +'.npy')\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Face Classifier\n",
    "\n",
    "\n",
    "#1 Load training data(numpy array of all person)\n",
    "     # x-value are stored in numpy\n",
    "     # y-value we need to allign for each person\n",
    "#2 Read video stream using opencv\n",
    "#3 Extract face out of it\n",
    "#4. Use knn to find predicted id to name of user\n",
    "#5. Display prediction on screen - bounding box and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x,y):\n",
    "    return np.sqrt(((x-y)**2).sum())\n",
    "\n",
    "def KNN(train , test,k=5):\n",
    "    dist = []\n",
    "    for i in range(train.shape[0]):\n",
    "        #get the vector (2-D matrix) and there respective labels\n",
    "        #like y = Ayush and x = array of data of pixels\n",
    "        ix = train[i,:-1]\n",
    "        iy = train[i,-1]\n",
    "        \n",
    "        #computing distance from test point\n",
    "        d = distance(test , ix)\n",
    "        dist.append([d,iy])\n",
    "        \n",
    "    #sorted the dist on basis of distance in ascending(like points which are near are kept early and opposite for other)\n",
    "    dk = sorted(dist , key = lambda x:x[0])\n",
    "    dk = dk[:k]\n",
    "    \n",
    "    #retrieving there labels from dk array for all rows and there respective label from -1 position in columns\n",
    "    labels = np.array(dk)[:,-1]\n",
    "    \n",
    "    #Getting there frequencies for each label\n",
    "    output = np.unique(labels , return_counts = True)\n",
    "    \n",
    "    #finding output from telling the element with max frequency and output their label as answer\n",
    "    index = np.argmax(output[1])\n",
    "    return output[0][index]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#starting the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#face Detection\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "skip=0\n",
    "dataset_path = './data/'\n",
    "face_data = []\n",
    "labels = []\n",
    "\n",
    "class_id = 0 #Labels for given file\n",
    "names = {} #mapping btw id and names\n",
    "\n",
    "#Data Preparation\n",
    "for fx in os.listdir(dataset_path):\n",
    "    if fx.endswith('.npy'):\n",
    "        #mapping btw id and name\n",
    "        #for eg name of file was ayush.npy then name[class_id] = ayush\n",
    "        names[class_id] = fx[:-4]\n",
    "        #loading value(array) into face_data\n",
    "        data_item = np.load(dataset_path + fx)\n",
    "        face_data.append(data_item)\n",
    "        \n",
    "        #creating labels for class i.e creating np array of one with size of shape of respective data_item and then multiplying with there class_id\n",
    "        target = class_id*np.ones((data_item.shape[0],))\n",
    "        class_id += 1\n",
    "        labels.append(target)\n",
    "        \n",
    "face_dataset = np.concatenate(face_data,axis = 0)\n",
    "face_labels = np.concatenate(labels , axis = 0).reshape((-1,1))\n",
    "\n",
    "trainset = np.concatenate((face_dataset , face_labels),axis = 1)\n",
    "trainset.shape\n",
    "# shape comes out to be (19,30001) which means data has 19 pictures of a person in it's data with 30,000 features and 1 label (Each)\n",
    "\n",
    "\n",
    "#testing phase\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if ret == False:\n",
    "        continue\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
    "    \n",
    "    for face in faces:\n",
    "        x,y,w,h = face\n",
    "        \n",
    "        #Get face Region Of Interest\n",
    "        offset = 10\n",
    "        face_section = frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        face_section = cv2.resize(face_section,(100,100))\n",
    "        \n",
    "        out = KNN(trainset , face_section.flatten())\n",
    "        pred = names[int(out)]\n",
    "        \n",
    "        \n",
    "        cv2.putText(frame , pred , (x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2,cv2.LINE_AA)\n",
    "        cv2.rectangle(frame , (x,y),(x+w,y+h) , (0,255,255),2)\n",
    "    cv2.imshow(\"Faces\",frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
